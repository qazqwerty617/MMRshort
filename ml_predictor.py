"""
ü§ñ ML PREDICTOR v1.0 - Machine Learning –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç XGBoost-–ø–æ–¥–æ–±–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º (Gradient Boosting) –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
—É—Å–ø–µ—Ö–∞ —Å–∏–≥–Ω–∞–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö.

–§–ò–õ–û–°–û–§–ò–Ø:
- –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ GOD BRAIN
- –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö WIN/LOSS
- –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É—Å–ø–µ—Ö–∞ –Ω–æ–≤–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞
"""

import sqlite3
import json
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from collections import defaultdict
import logging
import math
import pickle
import os

logger = logging.getLogger(__name__)

# –ü–æ–ø—Ä–æ–±—É–µ–º –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å sklearn, –µ—Å–ª–∏ –µ—Å—Ç—å
try:
    from sklearn.ensemble import GradientBoostingClassifier
    from sklearn.preprocessing import StandardScaler
    import numpy as np
    HAS_SKLEARN = True
    logger.info("ü§ñ ML Predictor: sklearn –¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º GradientBoosting")
except ImportError:
    HAS_SKLEARN = False
    logger.warning("ü§ñ ML Predictor: sklearn –ù–ï —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º")


class MLPredictor:
    """
    ü§ñ MACHINE LEARNING PREDICTOR
    
    –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —É—Å–ø–µ—Ö —Å–∏–≥–Ω–∞–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ:
    - –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ GOD BRAIN
    - Feature engineering (pump_pct, scores, hour, etc.)
    - Gradient Boosting –∏–ª–∏ –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º
    """
    
    def __init__(self, model_path: str = "data/ml_model.pkl"):
        self.model_path = model_path
        self.model = None
        self.scaler = None
        self.feature_names = [
            'pump_pct', 'combined_score', 'god_eye_score', 'dominator_score',
            'orderbook_score', 'oi_score', 'funding_score', 'btc_score', 
            'liq_score', 'pump_speed_minutes', 'hour'
        ]
        self.is_trained = False
        self.training_samples = 0
        
        # –î–ª—è –≤—Å—Ç—Ä–æ–µ–Ω–Ω–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ (–µ—Å–ª–∏ –Ω–µ—Ç sklearn)
        self.feature_weights = {}
        self.feature_thresholds = {}
        
        self._load_model()
    
    def _load_model(self):
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –µ—Å–ª–∏ –µ—Å—Ç—å."""
        if os.path.exists(self.model_path):
            try:
                with open(self.model_path, 'rb') as f:
                    data = pickle.load(f)
                    self.model = data.get('model')
                    self.scaler = data.get('scaler')
                    self.is_trained = data.get('is_trained', False)
                    self.training_samples = data.get('training_samples', 0)
                    self.feature_weights = data.get('feature_weights', {})
                    self.feature_thresholds = data.get('feature_thresholds', {})
                logger.info(f"ü§ñ ML Model –∑–∞–≥—Ä—É–∂–µ–Ω–∞ ({self.training_samples} samples)")
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ ML –º–æ–¥–µ–ª–∏: {e}")
    
    def _save_model(self):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å."""
        try:
            os.makedirs(os.path.dirname(self.model_path), exist_ok=True)
            with open(self.model_path, 'wb') as f:
                pickle.dump({
                    'model': self.model,
                    'scaler': self.scaler,
                    'is_trained': self.is_trained,
                    'training_samples': self.training_samples,
                    'feature_weights': self.feature_weights,
                    'feature_thresholds': self.feature_thresholds
                }, f)
            logger.info(f"ü§ñ ML Model —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è ML –º–æ–¥–µ–ª–∏: {e}")
    
    def train(self, db_path: str = "data/god_brain.db", min_samples: int = 20):
        """
        –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ GOD BRAIN.
        
        Args:
            db_path: –ü—É—Ç—å –∫ –±–∞–∑–µ GOD BRAIN
            min_samples: –ú–∏–Ω–∏–º—É–º —Å—ç–º–ø–ª–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        
        Returns:
            bool: –£—Å–ø–µ—à–Ω–æ –ª–∏ –æ–±—É—á–µ–Ω–∏–µ
        """
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT pump_pct, combined_score, god_eye_score, dominator_score,
                   orderbook_score, oi_score, funding_score, btc_score, 
                   liq_score, pump_speed_minutes, created_at, final_result
            FROM signal_memory
            WHERE final_result IS NOT NULL
        ''')
        
        rows = cursor.fetchall()
        conn.close()
        
        if len(rows) < min_samples:
            logger.info(f"ü§ñ ML: –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö ({len(rows)}/{min_samples})")
            return False
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        X = []
        y = []
        
        for row in rows:
            (pump_pct, combined, god_eye, dominator, ob, oi, funding, btc, 
             liq, speed, created, result) = row
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∞—Å
            try:
                hour = datetime.fromisoformat(created).hour if created else 12
            except:
                hour = 12
            
            features = [
                pump_pct or 0,
                combined or 5,
                god_eye or 5,
                dominator or 5,
                ob or 5,
                oi or 5,
                funding or 5,
                btc or 5,
                liq or 5,
                speed or 5,
                hour
            ]
            
            X.append(features)
            y.append(1 if result and result.startswith('WIN') else 0)
        
        self.training_samples = len(X)
        
        if HAS_SKLEARN:
            return self._train_sklearn(X, y)
        else:
            return self._train_builtin(X, y)
    
    def _train_sklearn(self, X: List, y: List) -> bool:
        """–û–±—É—á–µ–Ω–∏–µ —Å sklearn GradientBoosting."""
        try:
            import numpy as np
            
            X_arr = np.array(X)
            y_arr = np.array(y)
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            self.scaler = StandardScaler()
            X_scaled = self.scaler.fit_transform(X_arr)
            
            # –û–±—É—á–µ–Ω–∏–µ
            self.model = GradientBoostingClassifier(
                n_estimators=50,
                max_depth=3,
                learning_rate=0.1,
                random_state=42
            )
            self.model.fit(X_scaled, y_arr)
            self.is_trained = True
            
            # Feature importance
            importances = self.model.feature_importances_
            for i, name in enumerate(self.feature_names):
                self.feature_weights[name] = round(importances[i], 4)
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏
            sorted_features = sorted(self.feature_weights.items(), 
                                    key=lambda x: x[1], reverse=True)
            
            logger.info(f"ü§ñ ML Model –æ–±—É—á–µ–Ω–∞ –Ω–∞ {self.training_samples} samples")
            logger.info(f"ü§ñ Top features: {sorted_features[:3]}")
            
            self._save_model()
            return True
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è sklearn: {e}")
            return False
    
    def _train_builtin(self, X: List, y: List) -> bool:
        """–í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –æ–±—É—á–µ–Ω–∏—è (–±–µ–∑ sklearn)."""
        try:
            # –ü—Ä–æ—Å—Ç–æ–π feature importance –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º
            n = len(X)
            
            for i, name in enumerate(self.feature_names):
                feature_values = [x[i] for x in X]
                
                # –°—Ä–µ–¥–Ω–∏–µ –¥–ª—è WIN –∏ LOSS
                win_vals = [v for v, label in zip(feature_values, y) if label == 1]
                loss_vals = [v for v, label in zip(feature_values, y) if label == 0]
                
                win_avg = sum(win_vals) / len(win_vals) if win_vals else 5
                loss_avg = sum(loss_vals) / len(loss_vals) if loss_vals else 5
                
                # –í–∞–∂–Ω–æ—Å—Ç—å = —Ä–∞–∑–Ω–∏—Ü–∞ —Å—Ä–µ–¥–Ω–∏—Ö
                importance = win_avg - loss_avg
                self.feature_weights[name] = round(importance, 4)
                
                # –ü–æ—Ä–æ–≥ = —Å—Ä–µ–¥–Ω–µ–µ –¥–ª—è WIN
                self.feature_thresholds[name] = {
                    'win_avg': round(win_avg, 2),
                    'loss_avg': round(loss_avg, 2),
                    'threshold': round((win_avg + loss_avg) / 2, 2)
                }
            
            self.is_trained = True
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏
            sorted_features = sorted(self.feature_weights.items(), 
                                    key=lambda x: abs(x[1]), reverse=True)
            
            logger.info(f"ü§ñ ML Model (builtin) –æ–±—É—á–µ–Ω–∞ –Ω–∞ {self.training_samples} samples")
            logger.info(f"ü§ñ Top features: {sorted_features[:3]}")
            
            self._save_model()
            return True
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤—Å—Ç—Ä–æ–µ–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è: {e}")
            return False
    
    def predict(self, signal_data: Dict) -> Dict:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É—Å–ø–µ—Ö–∞ —Å–∏–≥–Ω–∞–ª–∞.
        
        Args:
            signal_data: {
                'pump_pct': float,
                'combined_score': float,
                'god_eye_score': float,
                ...
                'hour': int (optional)
            }
        
        Returns:
            {
                'probability': float (0-1),
                'prediction': str ('WIN' / 'LOSS'),
                'confidence': str ('HIGH' / 'MEDIUM' / 'LOW' / 'NO_MODEL'),
                'feature_contributions': dict,
                'recommendation': str
            }
        """
        if not self.is_trained:
            return {
                'probability': 0.5,
                'prediction': 'UNKNOWN',
                'confidence': 'NO_MODEL',
                'feature_contributions': {},
                'recommendation': '–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞ (–Ω—É–∂–Ω–æ –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö)'
            }
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ features
        hour = signal_data.get('hour', datetime.now().hour)
        features = [
            signal_data.get('pump_pct', 20),
            signal_data.get('combined_score', 5),
            signal_data.get('god_eye_score', 5),
            signal_data.get('dominator_score', 5),
            signal_data.get('orderbook_score', 5),
            signal_data.get('oi_score', 5),
            signal_data.get('funding_score', 5),
            signal_data.get('btc_score', 5),
            signal_data.get('liq_score', 5),
            signal_data.get('pump_speed_minutes', 5),
            hour
        ]
        
        if HAS_SKLEARN and self.model and self.scaler:
            return self._predict_sklearn(features)
        else:
            return self._predict_builtin(features)
    
    def _predict_sklearn(self, features: List) -> Dict:
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å sklearn."""
        try:
            import numpy as np
            
            X = np.array([features])
            X_scaled = self.scaler.transform(X)
            
            prob = self.model.predict_proba(X_scaled)[0][1]  # P(WIN)
            prediction = 'WIN' if prob >= 0.5 else 'LOSS'
            
            # Confidence
            if self.training_samples >= 50:
                confidence = 'HIGH'
            elif self.training_samples >= 20:
                confidence = 'MEDIUM'
            else:
                confidence = 'LOW'
            
            # Recommendation
            if prob >= 0.7:
                rec = 'üü¢ STRONG BUY - –≤—ã—Å–æ–∫–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É—Å–ø–µ—Ö–∞'
            elif prob >= 0.55:
                rec = 'üü° BUY - –Ω–æ—Ä–º–∞–ª—å–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å'
            elif prob >= 0.45:
                rec = '‚ö™ NEUTRAL - 50/50'
            elif prob >= 0.3:
                rec = 'üü† CAUTION - –Ω–∏–∑–∫–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å'
            else:
                rec = 'üî¥ AVOID - –æ—á–µ–Ω—å –Ω–∏–∑–∫–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å'
            
            return {
                'probability': round(prob, 3),
                'prediction': prediction,
                'confidence': confidence,
                'feature_contributions': self.feature_weights,
                'recommendation': rec,
                'training_samples': self.training_samples
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ sklearn –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
            return self._predict_builtin(features)
    
    def _predict_builtin(self, features: List) -> Dict:
        """–í—Å—Ç—Ä–æ–µ–Ω–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –±–µ–∑ sklearn."""
        try:
            # –°—á–∏—Ç–∞–µ–º score –Ω–∞ –æ—Å–Ω–æ–≤–µ feature weights
            score = 0
            contributions = {}
            
            for i, name in enumerate(self.feature_names):
                value = features[i]
                weight = self.feature_weights.get(name, 0)
                
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º contribution
                if name in self.feature_thresholds:
                    threshold = self.feature_thresholds[name]['threshold']
                    contrib = (value - threshold) * weight * 0.1
                else:
                    contrib = 0
                
                score += contrib
                contributions[name] = round(contrib, 3)
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å (sigmoid-like)
            prob = 1 / (1 + math.exp(-score)) if abs(score) < 10 else (1 if score > 0 else 0)
            prediction = 'WIN' if prob >= 0.5 else 'LOSS'
            
            # Confidence
            if self.training_samples >= 50:
                confidence = 'HIGH'
            elif self.training_samples >= 20:
                confidence = 'MEDIUM'
            else:
                confidence = 'LOW'
            
            # Recommendation
            if prob >= 0.7:
                rec = 'üü¢ STRONG BUY'
            elif prob >= 0.55:
                rec = 'üü° BUY'
            elif prob >= 0.45:
                rec = '‚ö™ NEUTRAL'
            elif prob >= 0.3:
                rec = 'üü† CAUTION'
            else:
                rec = 'üî¥ AVOID'
            
            return {
                'probability': round(prob, 3),
                'prediction': prediction,
                'confidence': confidence,
                'feature_contributions': contributions,
                'recommendation': rec,
                'training_samples': self.training_samples
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ builtin –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
            return {
                'probability': 0.5,
                'prediction': 'UNKNOWN',
                'confidence': 'ERROR',
                'feature_contributions': {},
                'recommendation': '–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è'
            }
    
    def get_status(self) -> Dict:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å ML –º–æ–¥–µ–ª–∏."""
        return {
            'is_trained': self.is_trained,
            'training_samples': self.training_samples,
            'has_sklearn': HAS_SKLEARN,
            'top_features': sorted(self.feature_weights.items(), 
                                  key=lambda x: abs(x[1]), reverse=True)[:5] if self.feature_weights else []
        }


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
_ml_predictor = None

def get_ml_predictor() -> MLPredictor:
    global _ml_predictor
    if _ml_predictor is None:
        _ml_predictor = MLPredictor()
    return _ml_predictor
